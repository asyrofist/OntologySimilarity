{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, Image\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook\n",
    "from IPython.display import SVG\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.layers import Input, Dense, LSTM, concatenate, Reshape\n",
    "from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    \n",
    "    hichy_ip = Input(shape = (None,2))\n",
    "    hichy1 = LSTM(64, stateful = False)(hichy_ip)\n",
    "    hichy3 = Dense(2, activation='sigmoid')(hichy1)\n",
    "\n",
    "    \n",
    "    model = Model(inputs=hichy_ip,outputs=hichy3)\n",
    "    opt=Adam(lr=0.0001)\n",
    "    l_val = \"binary_crossentropy\"\n",
    "    model.compile(loss=l_val, optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First Example\n",
    "# X is an array which does not have any different number of sequences\n",
    "# All the sequences are of length 4\n",
    "# So in LSTM Input, we have 3D data (batch_size, timesteps, features)\n",
    "\n",
    "# batch_size is the number of rows in the training data, but it can be any number smaller than total training data\n",
    "# if batch size is X.shape[0], then Network will be trained on the entire data at once\n",
    "# If batch_size < X.shape[0] (say 2) then Network will be trained first 2 rows, then next 2 rows , then next 2 rows so on.\n",
    "# if batch_size = 1, then Network will take one row at a time and train\n",
    "# so batch_size can be anything, if we know before hand then we can set it or set it as None\n",
    "\n",
    "# timesteps is the length of the sequences, here each row is a sequence for example,\n",
    "# [[-9.035250067710876, 213], [7.453250169754028, 213], [33.34074878692627, 213],[0, 0]] is s sequence\n",
    "# Now each sequence has 4 values(here each value is another array),\n",
    "# so time steps can be 4. Note that it can be variable too. So we can set it or set as None\n",
    "#***, in keras, number of timesteps should be same for all sequences other wise it will not work.\n",
    "\n",
    "# features is the number of columns for each data in sequences,\n",
    "# Here [-9.035250067710876, 213] is data. [7.453250169754028, 213] is data, [33.34074878692627, 213] is data\n",
    "# Here features is 2\n",
    "# *** in keras, this should same acorss all the sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4, 2)\n",
      "(6, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array([\n",
    "     [[-9.035250067710876, 213], [7.453250169754028, 213], [33.34074878692627, 213],[0, 0]],\n",
    "     [[-6.63700008392334, 213], [5.132999956607819, 213], [-6.63700008392334, 213],[0, 0]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213], [30.925999641418457, 213],[0, 0]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213], [30.925999641418457, 213],[0, 0]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213], [30.925999641418457, 213],[0, 0]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213], [30.925999641418457, 213],[0, 0]]\n",
    " ])\n",
    "\n",
    "Y = np.array([\n",
    "     [-9.035250067710876, 213],\n",
    "     [-6.63700008392334, 213],\n",
    "     [-5.1272499561309814, 213],\n",
    "     [-5.1272499561309814, 213],\n",
    "     [-5.1272499561309814, 213],\n",
    "    [-5.1272499561309814, 213]\n",
    " ])\n",
    "pprint(X.shape)\n",
    "pprint(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 1s 159ms/step - loss: -42.4613\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 916us/step - loss: -43.3664\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 865us/step - loss: -44.2668\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 2ms/step - loss: -45.0815\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 1ms/step - loss: -45.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb2f983630>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epoch is for each batch\n",
    "# We are passing entire X to the model, which will be faster\n",
    "model = get_net()\n",
    "model.fit(X, Y, batch_size =X.shape[0], epochs = 5,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "(6, 2)\n"
     ]
    }
   ],
   "source": [
    "# timesteps - test cases\n",
    "# Suppose my data look like this\n",
    "# The second and fourth sequence are of length 3 and rest are of length 4\n",
    "X = np.array([\n",
    "     [[-9.035250067710876, 213], [7.453250169754028, 213], [33.34074878692627, 213],[0, 0]],\n",
    "     [[-6.63700008392334, 213], [5.132999956607819, 213], [-6.63700008392334, 213]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213], [30.925999641418457, 213],[0, 0]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213], [30.925999641418457, 213]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213], [30.925999641418457, 213],[0, 0]],\n",
    "     [[-5.1272499561309814, 213], [8.251499891281128, 213]]\n",
    " ])\n",
    "\n",
    "Y = np.array([\n",
    "     [-9.035250067710876, 213],\n",
    "     [-6.63700008392334, 213],\n",
    "     [-5.1272499561309814, 213],\n",
    "     [-5.1272499561309814, 213],\n",
    "     [-5.1272499561309814, 213],\n",
    "    [-5.1272499561309814, 213]\n",
    " ])\n",
    "\n",
    "#here shape gives this (6,) which is incomple because we have different sequences length\n",
    "pprint(X.shape) \n",
    "pprint(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_14 to have 3 dimensions, but got array with shape (6, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b74b81e7e139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This will give error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1412\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1415\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_14 to have 3 dimensions, but got array with shape (6, 1)"
     ]
    }
   ],
   "source": [
    "# This will give error\n",
    "model = get_net()\n",
    "model.fit(X, Y, batch_size =X.shape[0], epochs = 5,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the above will give error, to tackle this we can do follwing things\n",
    "# 1) use one row at a time to train, so instead of passing entire training data/ batch data, feed one by one. \n",
    "# in this case sequence length will not matter as we are passing only one sequence, but this will take long time.\n",
    "# 2) use padding, pad zeros to the smaller length sequences but this might change the data and network will be get affected.\n",
    "# 3) use bucket, create different batches, each batch will have only the sequences that has same length \n",
    "# or such range that we need to pad very small sequences in batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 1s/step - loss: -89.6085\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: -90.7044\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: -91.6412\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: -92.7277\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: -93.8092\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: -142.8878\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: -143.4636\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: -144.1100\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: -144.8036\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 12ms/step - loss: -145.5310\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: -100.8017\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: -101.5367\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: -102.3362\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 14ms/step - loss: -103.1847\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 18ms/step - loss: -104.0711\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 17ms/step - loss: -141.9537\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 9ms/step - loss: -142.5063\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 27ms/step - loss: -143.1179\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 11ms/step - loss: -143.7760\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 13ms/step - loss: -144.4723\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 26ms/step - loss: -108.7192\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: -109.4402\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: -110.2252\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 8ms/step - loss: -111.0480\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 15ms/step - loss: -111.9105\n",
      "Epoch 1/5\n",
      "1/1 [==============================] - 0s 4ms/step - loss: -152.1685\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: -152.6234\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: -153.1284\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: -153.6744\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 6ms/step - loss: -154.2546\n"
     ]
    }
   ],
   "source": [
    "# 1) use one row at a time to train, so instead of passing entire training data/ batch data, feed one by one. \n",
    "# in this case sequence length will not matter as we are passing only one sequence, but this will take long time.\n",
    "model = get_net()\n",
    "for t_x, t_y in zip(X, Y):\n",
    "    t_x = np.array(t_x)\n",
    "    t_y = np.array(t_y)\n",
    "    t_x = t_x.reshape(1, t_x.shape[0], t_x.shape[1])\n",
    "    t_y = t_y.reshape(1, t_y.shape[0])\n",
    "    model.fit(t_x, t_y, batch_size =1, epochs = 5,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ -9, 213],\n",
       "        [  7, 213],\n",
       "        [ 33, 213],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[  0,   0],\n",
       "        [ -6, 213],\n",
       "        [  5, 213],\n",
       "        [ -6, 213]],\n",
       "\n",
       "       [[ -5, 213],\n",
       "        [  8, 213],\n",
       "        [ 30, 213],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[  0,   0],\n",
       "        [ -5, 213],\n",
       "        [  8, 213],\n",
       "        [ 30, 213]],\n",
       "\n",
       "       [[ -5, 213],\n",
       "        [  8, 213],\n",
       "        [ 30, 213],\n",
       "        [  0,   0]],\n",
       "\n",
       "       [[  0,   0],\n",
       "        [  0,   0],\n",
       "        [ -5, 213],\n",
       "        [  8, 213]]], dtype=int32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2) use padding, pad zeros to the smaller length sequences but this might change the data and network will be get affected.\n",
    "maxlen = 4\n",
    "X = sequence.pad_sequences(X, maxlen=maxlen) # padded at the begining\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6/6 [==============================] - 1s 206ms/step - loss: 32.7035\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 0s 796us/step - loss: 32.0855\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 0s 803us/step - loss: 31.4683\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 0s 923us/step - loss: 30.8520\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 30.2741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb3294d1d0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_net()\n",
    "model.fit(X, Y, batch_size =X.shape[0], epochs = 5,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) use bucket, create different batches, each batch will have only the sequences that has same length \n",
    "# or such range that we need to pad very small sequences in batch.\n",
    "batch1_x = []\n",
    "batch1_x.append(X[0]) # sequence length - 4\n",
    "batch1_x.append(X[2]) # sequence length - 4\n",
    "batch1_x.append(X[4]) # sequence length - 4\n",
    "\n",
    "batch1_y = []\n",
    "batch1_y.append(Y[0])\n",
    "batch1_y.append(Y[2])\n",
    "batch1_y.append(Y[4])\n",
    "\n",
    "batch2_x = []\n",
    "batch2_x.append(X[1]) # sequence length - 3\n",
    "batch2_x.append(X[3]) # sequence length - 2\n",
    "\n",
    "maxlen = 3\n",
    "batch2_x = sequence.pad_sequences(batch2_x, maxlen=maxlen) # padded at the begining\n",
    "\n",
    "batch2_y = []\n",
    "batch2_y.append(Y[1])\n",
    "batch2_y.append(Y[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3/3 [==============================] - 1s 461ms/step - loss: -9.2587\n",
      "Epoch 2/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -10.4746\n",
      "Epoch 3/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -11.6964\n",
      "Epoch 4/5\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -12.9237\n",
      "Epoch 5/5\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -14.1561\n",
      "Epoch 1/5\n",
      "2/2 [==============================] - 0s 3ms/step - loss: -20.8671\n",
      "Epoch 2/5\n",
      "2/2 [==============================] - 0s 3ms/step - loss: -21.7794\n",
      "Epoch 3/5\n",
      "2/2 [==============================] - 0s 3ms/step - loss: -22.7388\n",
      "Epoch 4/5\n",
      "2/2 [==============================] - 0s 5ms/step - loss: -23.7328\n",
      "Epoch 5/5\n",
      "2/2 [==============================] - 0s 6ms/step - loss: -24.7532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb327444a8>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_net()\n",
    "batch1_x = np.array(batch1_x)\n",
    "batch1_y = np.array(batch1_y)\n",
    "model.fit(batch1_x, batch1_y, batch_size =batch1_x.shape[0], epochs = 5,  verbose = 1)\n",
    "\n",
    "batch2_x = np.array(batch2_x)\n",
    "batch2_y = np.array(batch2_y)\n",
    "model.fit(batch2_x, batch2_y, batch_size =batch2_x.shape[0], epochs = 5,  verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
